{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16108fa",
   "metadata": {},
   "source": [
    "# Stemming y Lematización\n",
    "Suárez Pérez Juan Pablo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db41198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias.\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09671c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\USUARIO\n",
      "[nltk_data]     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\USUARIO\n",
      "[nltk_data]     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\USUARIO\n",
      "[nltk_data]     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incialziación del ambiente.\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953a4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicalización de ejemplos. \n",
    "example_words = ['Generous', 'General', 'Generosity', 'Generousness', 'Generally', 'Students']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afabd1ca",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d08c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciación de la clase PorterStemmer.\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03761a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "Generous            gener               \n",
      "General             gener               \n",
      "Generosity          generos             \n",
      "Generousness        gener               \n",
      "Generally           gener               \n",
      "Students            student             \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las raíces de las palabras.\n",
    "print('{:20}{:20}'.format('--Word--', '--Stem--'))\n",
    "for word in example_words:\n",
    "    print('{:20}{:20}'.format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4a9b9",
   "metadata": {},
   "source": [
    "## Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f6dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciación de la clase WordNetLemmatizer.\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503e7c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "Generous            Generous            \n",
      "General             General             \n",
      "Generosity          Generosity          \n",
      "Generousness        Generousness        \n",
      "Generally           Generally           \n",
      "Students            Students            \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los lemmas de las palabras. \n",
    "print('{:20}{:20}'.format('--Word--', '--Lemma--'))\n",
    "for word in example_words:\n",
    "    print('{:20}{:20}'.format(word, wnl.lemmatize(word, pos='v')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7de246",
   "metadata": {},
   "source": [
    "## Stemming y Lematización con ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb22e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos los ejemplos\n",
    "#example_sentence_1 = 'If you are not willing to risk the usual, you will have to settle for the ordinary, you only fail when you just not try'\n",
    "example_sentence_2 = 'After finishing her exams, which she had been preparing for tirelessly, Sarah decided to treat herself to a relaxing weekend getaway, during which she explored the picturesque countryside and indulged in delicious local cuisine, ultimately finding the peace and rejuvenation she desperately needed after months of hard work.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709cef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos los signos de puntuación de la oración. \n",
    "example_sentence_no_punct = example_sentence_2.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eca4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos los tokens de la oración. \n",
    "word_tokens = word_tokenize(example_sentence_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31e1114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "After               after               \n",
      "finishing           finish              \n",
      "her                 her                 \n",
      "exams               exam                \n",
      "which               which               \n",
      "she                 she                 \n",
      "had                 had                 \n",
      "been                been                \n",
      "preparing           prepar              \n",
      "for                 for                 \n",
      "tirelessly          tirelessli          \n",
      "Sarah               sarah               \n",
      "decided             decid               \n",
      "to                  to                  \n",
      "treat               treat               \n",
      "herself             herself             \n",
      "to                  to                  \n",
      "a                   a                   \n",
      "relaxing            relax               \n",
      "weekend             weekend             \n",
      "getaway             getaway             \n",
      "during              dure                \n",
      "which               which               \n",
      "she                 she                 \n",
      "explored            explor              \n",
      "the                 the                 \n",
      "picturesque         picturesqu          \n",
      "countryside         countrysid          \n",
      "and                 and                 \n",
      "indulged            indulg              \n",
      "in                  in                  \n",
      "delicious           delici              \n",
      "local               local               \n",
      "cuisine             cuisin              \n",
      "ultimately          ultim               \n",
      "finding             find                \n",
      "the                 the                 \n",
      "peace               peac                \n",
      "and                 and                 \n",
      "rejuvenation        rejuven             \n",
      "she                 she                 \n",
      "desperately         desper              \n",
      "needed              need                \n",
      "after               after               \n",
      "months              month               \n",
      "of                  of                  \n",
      "hard                hard                \n",
      "work                work                \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las ráices de los tokens.\n",
    "print('{:20}{:20}'.format('--Word--', '--Stem--'))\n",
    "for word in word_tokens:\n",
    "    print('{:20}{:20}'.format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00458fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "After               After               \n",
      "finishing           finish              \n",
      "her                 her                 \n",
      "exams               exams               \n",
      "which               which               \n",
      "she                 she                 \n",
      "had                 have                \n",
      "been                be                  \n",
      "preparing           prepare             \n",
      "for                 for                 \n",
      "tirelessly          tirelessly          \n",
      "Sarah               Sarah               \n",
      "decided             decide              \n",
      "to                  to                  \n",
      "treat               treat               \n",
      "herself             herself             \n",
      "to                  to                  \n",
      "a                   a                   \n",
      "relaxing            relax               \n",
      "weekend             weekend             \n",
      "getaway             getaway             \n",
      "during              during              \n",
      "which               which               \n",
      "she                 she                 \n",
      "explored            explore             \n",
      "the                 the                 \n",
      "picturesque         picturesque         \n",
      "countryside         countryside         \n",
      "and                 and                 \n",
      "indulged            indulge             \n",
      "in                  in                  \n",
      "delicious           delicious           \n",
      "local               local               \n",
      "cuisine             cuisine             \n",
      "ultimately          ultimately          \n",
      "finding             find                \n",
      "the                 the                 \n",
      "peace               peace               \n",
      "and                 and                 \n",
      "rejuvenation        rejuvenation        \n",
      "she                 she                 \n",
      "desperately         desperately         \n",
      "needed              need                \n",
      "after               after               \n",
      "months              months              \n",
      "of                  of                  \n",
      "hard                hard                \n",
      "work                work                \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los lemmas de los tokens.\n",
    "print('{:20}{:20}'.format('--Word--', '--Lemma--'))\n",
    "for word in word_tokens:\n",
    "    print('{:20}{:20}'.format(word, wnl.lemmatize(word, pos='v')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
