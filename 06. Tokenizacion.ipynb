{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60aa155",
   "metadata": {},
   "source": [
    "# Tokenización\n",
    "Suárez Pérez Juan Pablo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab64f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias.\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdffe436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de Tokenizador. \n",
    "def tokenizador(texto):\n",
    "    \"\"\"\n",
    "        Tokenizador de texto por palabras. \n",
    "        Entadas: texto.\n",
    "        Salidas: tokens.\n",
    "    \"\"\"\n",
    "    # Utilizamos una expresión regular para dividir el texto en tokens.\n",
    "    tokens = re.split(r'(\\W+)', texto)\n",
    "    # Volvemos minúsculas.\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    # Eliminamos tokens vacíos y signos de puntuación solos.\n",
    "    tokens = [token for token in tokens if token.strip()]\n",
    "    # Retornamos los valores.\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f0165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿¡', 'quién', '! ', 'eres', '?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementación del Tokenizador. \n",
    "texto = \"¿¡Quién! eres?\"\n",
    "tokenizador(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad8fc0",
   "metadata": {},
   "source": [
    "## Ejemplo con oración en inglés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f2f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización del ambiente. \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "interrogative_sentences = 'what is the weather like today?' \n",
    "declarative_sentence = 'The weather is sunny' \n",
    "complex_sentence = 'I went to the store, but they wew clased, so i had to go another store.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f162e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento interrogativo:\n",
      "what PRON\n",
      "is AUX\n",
      "the DET\n",
      "weather NOUN\n",
      "like ADP\n",
      "today NOUN\n",
      "? PUNCT\n",
      "\n",
      "Documento declarativo:\n",
      "The DET\n",
      "weather NOUN\n",
      "is AUX\n",
      "sunny ADJ\n",
      "\n",
      "Oracion compleja:\n",
      "I PRON\n",
      "went VERB\n",
      "to ADP\n",
      "the DET\n",
      "store NOUN\n",
      ", PUNCT\n",
      "but CCONJ\n",
      "they PRON\n",
      "wew VERB\n",
      "clased VERB\n",
      ", PUNCT\n",
      "so CCONJ\n",
      "i PRON\n",
      "had VERB\n",
      "to PART\n",
      "go VERB\n",
      "another DET\n",
      "store NOUN\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtención de los tokens. \n",
    "doc_1 = nlp(interrogative_sentences)\n",
    "doc_2 = nlp(declarative_sentence)\n",
    "doc_3 = nlp(complex_sentence)\n",
    "\n",
    "# Generación de diccionario.\n",
    "compil = {\n",
    "    'Documento interrogativo:' : doc_1, \n",
    "    'Documento declarativo:' : doc_2, \n",
    "    'Oracion compleja:' : doc_3    \n",
    "}\n",
    "\n",
    "# Impresión de los tokens y tags. \n",
    "for doc in compil.keys():\n",
    "    print(doc)\n",
    "    # Imprimimos el analisis\n",
    "    for token in compil[doc]:\n",
    "        print(token.text, token.pos_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f9376",
   "metadata": {},
   "source": [
    "## Ejemplo con oración en español. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed095f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización del ambiente. \n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "interrogative_sentences = '¿Hace mucho calor?' \n",
    "declarative_sentence = 'El clima esta muy caliente.' \n",
    "complex_sentence = 'Fui a la tienda, pero estaba cerrada, así que tuve que ir a otra tienda.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2c1edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento interrogativo:\n",
      "¿ PUNCT\n",
      "Hace VERB\n",
      "mucho DET\n",
      "calor NOUN\n",
      "? PUNCT\n",
      "\n",
      "Documento declarativo:\n",
      "El DET\n",
      "clima NOUN\n",
      "esta DET\n",
      "muy ADV\n",
      "caliente ADJ\n",
      ". PUNCT\n",
      "\n",
      "Oracion compleja:\n",
      "Fui AUX\n",
      "a ADP\n",
      "la DET\n",
      "tienda NOUN\n",
      ", PUNCT\n",
      "pero CCONJ\n",
      "estaba AUX\n",
      "cerrada ADJ\n",
      ", PUNCT\n",
      "así ADV\n",
      "que SCONJ\n",
      "tuve VERB\n",
      "que SCONJ\n",
      "ir VERB\n",
      "a ADP\n",
      "otra DET\n",
      "tienda NOUN\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtención de los tokens. \n",
    "doc_1 = nlp(interrogative_sentences)\n",
    "doc_2 = nlp(declarative_sentence)\n",
    "doc_3 = nlp(complex_sentence)\n",
    "\n",
    "# Generación de diccionario.\n",
    "compil = {\n",
    "    'Documento interrogativo:' : doc_1, \n",
    "    'Documento declarativo:' : doc_2, \n",
    "    'Oracion compleja:' : doc_3    \n",
    "}\n",
    "\n",
    "# Impresión de los tokens y tags. \n",
    "for doc in compil.keys():\n",
    "    print(doc)\n",
    "    # Imprimimos el analisis\n",
    "    for token in compil[doc]:\n",
    "        print(token.text, token.pos_)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
