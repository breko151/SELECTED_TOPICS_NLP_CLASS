{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "82e51282c3a54b93aa06a2bc2d38f941",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6954,
    "execution_start": 1696613429994,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO DELL\\anaconda3\\envs\\selected_topics_NLP_class\\lib\\runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "28c45ba4beb44306b1c9c845d96af046",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1043,
    "execution_start": 1696613436501,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# crear gramáticas con nltk y crear herramientas que nos permitan realizar análisis sintáctico para oraciones sencillas\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3e8191ca77694f62b463ae1a68596ae6",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Gramáticas independientes del Contexto (CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a7e355039adf40ad88c411ede03db19e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Jerarquía de lenguajes y gramática formales para modelar fenómenos ligústicos de las lenguas naturales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2347c7e5ffd34a75818d7111eee6f219",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Conjunto de reglas y restricciones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5f1b86d4f1094202a9728760fed18ec4",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Símbolos no terminales: componentes intermedios que utilizamos en las reglas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fcc1df2c83fa4bbfa2a5770c15c2fb1d",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Símbolos terminales: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5b1baaf1e3b6440185e04d2979d9c0cc",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### Gramáticas Generativas en NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "66a49cfe7fc94b78b8fa2ab073d799fd",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5538c89d8cda44ac92aa19b98ccabbc8",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "g1 = \" \" \" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0956cf5fe28c46aa993617535d2058b6",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "s -> NP VP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f7b32c55d6ba40c89481c77b6afab1e4",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "NP -> DET N | DET N PP| ' I '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "419fbc4fdf1c473894dc92f6870e7ec2",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "VP -> V NP | VP PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b4a61c86a5ea456cab7c027736be6619",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "PP -> P NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a852c3d0ba7b47e5a8efec55305897a9",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Det -> 'an' | 'my'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f55da729288a4c57ae9249bf6dab3cc1",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "N -> 'elephant' | 'pijamas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c5bd87ce653b4aabbc23c49d05c030cb",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "V -> 'shot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "90643604d1514dad86a49860db7018ea",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "P -> 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "09c86b5fdfab4c108bcb35c0bbe3706f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "\" \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "6afc086613d844d8ac035945c43d85a6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1696613472960,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "g1 = \"\"\" \n",
    "s -> NP VP\n",
    "NP -> Det N | Det N PP| 'I'\n",
    "VP -> V NP | VP PP\n",
    "PP -> P NP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "c2b3796a75704386b4c165bdd44a5853",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 59,
    "execution_start": 1696613475850,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = s)\n",
      "    s -> NP VP\n",
      "    NP -> Det N\n",
      "    NP -> Det N PP\n",
      "    NP -> 'I'\n",
      "    VP -> V NP\n",
      "    VP -> VP PP\n",
      "    PP -> P NP\n",
      "    Det -> 'an'\n",
      "    Det -> 'my'\n",
      "    N -> 'elephant'\n",
      "    N -> 'pajamas'\n",
      "    V -> 'shot'\n",
      "    P -> 'in'\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.CFG.fromstring(g1) #se crea el \"esqueleto\"\n",
    "print(grammar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "9af6541a392642c69d6811b738ac7415",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1696613478336,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "analyzer = nltk.ChartParser(grammar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "afe0ebb38db04e698c517f6dccce49d3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1696613479729,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(s\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "oracion = \"I shot an elephant in my pajamas\".split()\n",
    "trees1 = analyzer.parse(oracion)\n",
    "for tree in trees1:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "708b80eced184541a001491fc4ff2a30",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1696613482616,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n"
     ]
    }
   ],
   "source": [
    "print(analyzer.parse_one(oracion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "ca40af6e57f241cdac5bf5f94ddeb54f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 31,
    "execution_start": 1696613437538,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "g1v2 = \"\"\" \n",
    "S -> NP VP\n",
    "NP -> Det N | Det N PP| PRO\n",
    "VP -> V NP | VP PP\n",
    "PP -> P NP\n",
    "Det -> 'an' | 'my'\n",
    "PRO -> 'I' | 'you'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "1c83e4ec293f4fc2a17a58803ecda621",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 30,
    "execution_start": 1696613437538,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 15 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det N\n",
      "    NP -> Det N PP\n",
      "    NP -> PRO\n",
      "    VP -> V NP\n",
      "    VP -> VP PP\n",
      "    PP -> P NP\n",
      "    Det -> 'an'\n",
      "    Det -> 'my'\n",
      "    PRO -> 'I'\n",
      "    PRO -> 'you'\n",
      "    N -> 'elephant'\n",
      "    N -> 'pajamas'\n",
      "    V -> 'shot'\n",
      "    P -> 'in'\n"
     ]
    }
   ],
   "source": [
    "grammar1v2 = nltk.CFG.fromstring(g1v2) #se crea el \"esqueleto\"\n",
    "print(grammar1v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "a2d1a3c78ff44431bffe14f4d6ec72e2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 27,
    "execution_start": 1696613437547,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "analyzer = nltk.ChartParser(grammar1v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "9f3f47dd7d3341e7a55c44cdc1974f41",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1696613437552,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PRO I))\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP (PRO I))\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "oracion = \"I shot an elephant in my pajamas\".split()\n",
    "trees1 = analyzer.parse(oracion)\n",
    "for tree in trees1:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "09f152a1f6b54140912c5f3bbb7cfe88",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 28,
    "execution_start": 1696613437559,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PRO I))\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n"
     ]
    }
   ],
   "source": [
    "print(analyzer.parse_one(oracion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "90d689a7776d4ba1b63e1b96df841bd1",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Cuando tenemos un error en la redacción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "af34be779dde4b26839b67d2e157286e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1696613713729,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El analisis sintactico es el siguiente\n"
     ]
    }
   ],
   "source": [
    "oracion2 = \"shot an pajamas elephant my I\".split()\n",
    "print(\"El analisis sintactico es el siguiente\")\n",
    "for tree in analyzer.parse(oracion2):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2e186bf086a6425d893b1a970a835927",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Cuando no tenemos las palabras en nuestro diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "f0ce1596a8df449fb67989b862e3b3e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 919,
    "execution_start": 1696613755123,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El analisis sintactico es el siguiente\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'our', 'time', 'is', 'running', 'out'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m oracion3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mour time is running out\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl analisis sintactico es el siguiente\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43moracion3\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tree)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\selected_topics_NLP_class\\lib\\site-packages\\nltk\\parse\\chart.py:1474\u001b[0m, in \u001b[0;36mChartParser.parse\u001b[1;34m(self, tokens, tree_class)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens, tree_class\u001b[38;5;241m=\u001b[39mTree):\n\u001b[1;32m-> 1474\u001b[0m     chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchart_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(chart\u001b[38;5;241m.\u001b[39mparses(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mstart(), tree_class\u001b[38;5;241m=\u001b[39mtree_class))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\selected_topics_NLP_class\\lib\\site-packages\\nltk\\parse\\chart.py:1432\u001b[0m, in \u001b[0;36mChartParser.chart_parse\u001b[1;34m(self, tokens, trace)\u001b[0m\n\u001b[0;32m   1429\u001b[0m trace_new_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_new_edges\n\u001b[0;32m   1431\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokens)\n\u001b[1;32m-> 1432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grammar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1433\u001b[0m chart \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chart_class(tokens)\n\u001b[0;32m   1434\u001b[0m grammar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\selected_topics_NLP_class\\lib\\site-packages\\nltk\\grammar.py:665\u001b[0m, in \u001b[0;36mCFG.check_coverage\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m    664\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m missing)\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    666\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar does not cover some of the \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput words: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m missing\n\u001b[0;32m    667\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'our', 'time', 'is', 'running', 'out'\"."
     ]
    }
   ],
   "source": [
    "oracion3 = \"our time is running out\".split()\n",
    "print(\"El analisis sintactico es el siguiente\")\n",
    "for tree in analyzer.parse(oracion3):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9d0ed157d0544f57be5f4875de1ee1e8",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Realizar el analizador sintactico de la siguientes oraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2c0fa507c2bf4aae95347a71004e3902",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Mañana es viernes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ccc99ebd9deb460989f159a479dc91f0",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Hoy es jueves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9c683f4a0f2c4fb582dbb5d217a72bb9",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Téneis sueño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "17b8ef709d0b4ba6998bdb05474a0432",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Hace frío"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6f1314418d634052a733fc6b380078a5",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Pepe hace sueño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "c9c6d38ace214d34a19d83e704875de4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1696614473636,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "oraciones = \"\"\" mañana es viernes\n",
    "hoy es jueves\n",
    "tenéis sueño\n",
    "hace frio\n",
    "Pepe hace sueño\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "94805f723e884df195e36a4dfdd47fc2",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "c38e718a6d654d639c91071a7a6e9ecc",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "g1 = \"\"\"\n",
    "S -> NP VP\n",
    "NP -> Pronoun | ProperNoun\n",
    "VP -> Verb | Verb NP | Verb NP NP\n",
    "Pronoun -> 'mañana' | 'hoy' | 'tenéis' | 'hace'\n",
    "ProperNoun -> 'viernes' | 'jueves' | 'sueño' | 'frio' | 'Pepe'\n",
    "Verb -> 'es' | 'hace'\n",
    "\"\"\"\n",
    "grammar1 = nltk.CFG.fromstring(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración:  mañana es viernes\n",
      "(S (NP (Pronoun mañana)) (VP (Verb es) (NP (ProperNoun viernes))))\n",
      "\n",
      "---\n",
      "\n",
      "Oración: hoy es jueves\n",
      "(S (NP (Pronoun hoy)) (VP (Verb es) (NP (ProperNoun jueves))))\n",
      "\n",
      "---\n",
      "\n",
      "Oración: tenéis sueño\n",
      "\n",
      "---\n",
      "\n",
      "Oración: hace frio\n",
      "\n",
      "---\n",
      "\n",
      "Oración: Pepe hace sueño\n",
      "(S (NP (ProperNoun Pepe)) (VP (Verb hace) (NP (ProperNoun sueño))))\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar1)\n",
    "for oracion in oraciones:\n",
    "    if oracion:\n",
    "        tokens = oracion.split()\n",
    "        parse_trees = list(parser.parse(tokens))\n",
    "        print(f\"Oración: {oracion}\")\n",
    "        for tree in parse_trees:\n",
    "            print(tree)\n",
    "        print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=1426afb8-3aaf-4cf4-a1df-a635fc5b51ca' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "61f18bb87ae44569a5a5addba7dc5acf",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
