{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16108fa",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db41198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers\\averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Unzipping models\\moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping misc\\perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers\\rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars\\spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping models\\word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to C:\\Users\\USUARIO\n",
      "[nltk_data]    |     DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora\\ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09671c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d08c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "953a4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_words = ['Generous', 'General', 'Generosity', 'Generousness', 'Generally', 'Students']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03761a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "Generous            gener               \n",
      "General             gener               \n",
      "Generosity          generos             \n",
      "Generousness        gener               \n",
      "Generally           gener               \n",
      "Students            student             \n"
     ]
    }
   ],
   "source": [
    "print('{:20}{:20}'.format('--Word--', '--Stem--'))\n",
    "for word in example_words:\n",
    "    print('{:20}{:20}'.format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40779c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89f6dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "503e7c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "Generous            Generous            \n",
      "General             General             \n",
      "Generosity          Generosity          \n",
      "Generousness        Generousness        \n",
      "Generally           Generally           \n",
      "Students            Students            \n"
     ]
    }
   ],
   "source": [
    "print('{:20}{:20}'.format('--Word--', '--Lemma--'))\n",
    "for word in example_words:\n",
    "    print('{:20}{:20}'.format(word, wnl.lemmatize(word, pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd424f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb22e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_sentence = 'If you are not willing to risk the usual, you will have to settle for the ordinary, you only fail when you just not try'\n",
    "example_sentence = 'After finishing her exams, which she had been preparing for tirelessly, Sarah decided to treat herself to a relaxing weekend getaway, during which she explored the picturesque countryside and indulged in delicious local cuisine, ultimately finding the peace and rejuvenation she desperately needed after months of hard work.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "709cef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence_no_punct = example_sentence.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3eca4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(example_sentence_no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d31e1114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Stem--            \n",
      "After               after               \n",
      "finishing           finish              \n",
      "her                 her                 \n",
      "exams               exam                \n",
      "which               which               \n",
      "she                 she                 \n",
      "had                 had                 \n",
      "been                been                \n",
      "preparing           prepar              \n",
      "for                 for                 \n",
      "tirelessly          tirelessli          \n",
      "Sarah               sarah               \n",
      "decided             decid               \n",
      "to                  to                  \n",
      "treat               treat               \n",
      "herself             herself             \n",
      "to                  to                  \n",
      "a                   a                   \n",
      "relaxing            relax               \n",
      "weekend             weekend             \n",
      "getaway             getaway             \n",
      "during              dure                \n",
      "which               which               \n",
      "she                 she                 \n",
      "explored            explor              \n",
      "the                 the                 \n",
      "picturesque         picturesqu          \n",
      "countryside         countrysid          \n",
      "and                 and                 \n",
      "indulged            indulg              \n",
      "in                  in                  \n",
      "delicious           delici              \n",
      "local               local               \n",
      "cuisine             cuisin              \n",
      "ultimately          ultim               \n",
      "finding             find                \n",
      "the                 the                 \n",
      "peace               peac                \n",
      "and                 and                 \n",
      "rejuvenation        rejuven             \n",
      "she                 she                 \n",
      "desperately         desper              \n",
      "needed              need                \n",
      "after               after               \n",
      "months              month               \n",
      "of                  of                  \n",
      "hard                hard                \n",
      "work                work                \n"
     ]
    }
   ],
   "source": [
    "print('{:20}{:20}'.format('--Word--', '--Stem--'))\n",
    "for word in word_tokens:\n",
    "    print('{:20}{:20}'.format(word, ps.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00458fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Word--            --Lemma--           \n",
      "After               After               \n",
      "finishing           finish              \n",
      "her                 her                 \n",
      "exams               exams               \n",
      "which               which               \n",
      "she                 she                 \n",
      "had                 have                \n",
      "been                be                  \n",
      "preparing           prepare             \n",
      "for                 for                 \n",
      "tirelessly          tirelessly          \n",
      "Sarah               Sarah               \n",
      "decided             decide              \n",
      "to                  to                  \n",
      "treat               treat               \n",
      "herself             herself             \n",
      "to                  to                  \n",
      "a                   a                   \n",
      "relaxing            relax               \n",
      "weekend             weekend             \n",
      "getaway             getaway             \n",
      "during              during              \n",
      "which               which               \n",
      "she                 she                 \n",
      "explored            explore             \n",
      "the                 the                 \n",
      "picturesque         picturesque         \n",
      "countryside         countryside         \n",
      "and                 and                 \n",
      "indulged            indulge             \n",
      "in                  in                  \n",
      "delicious           delicious           \n",
      "local               local               \n",
      "cuisine             cuisine             \n",
      "ultimately          ultimately          \n",
      "finding             find                \n",
      "the                 the                 \n",
      "peace               peace               \n",
      "and                 and                 \n",
      "rejuvenation        rejuvenation        \n",
      "she                 she                 \n",
      "desperately         desperately         \n",
      "needed              need                \n",
      "after               after               \n",
      "months              months              \n",
      "of                  of                  \n",
      "hard                hard                \n",
      "work                work                \n"
     ]
    }
   ],
   "source": [
    "print('{:20}{:20}'.format('--Word--', '--Lemma--'))\n",
    "for word in word_tokens:\n",
    "    print('{:20}{:20}'.format(word, wnl.lemmatize(word, pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14193077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c1cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25db369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf5524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e2b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cefd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb677751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f00ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e6f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ba680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8ad24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
